The goal of this project is to develop a domain-specific application that combines the strengths of a Large Language Model (LLM) with the efficiency of a vector database for data storage and retrieval. Using Retrieval-Augmented Generation (RAG) for the method and Streamlit for the front-end, the application is built with Python.

Technology Stack:
Frontend: Streamlit for building the user interface.
Vector Database: Pinecone for efficient data storage and retrieval.
LLM: OpenAI model for natural language processing and query handling.
Backend: LangChain framework utilizing the RAG method.
